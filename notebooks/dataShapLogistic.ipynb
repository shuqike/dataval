{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../src/DataShap/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from DShap import DShap\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sk_utils import *\n",
    "%matplotlib inline\n",
    "MEM_DIR = './'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a calssification problem and use the a losigitic regression model for a small data set of size 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem, model = 'classification', 'logistic'\n",
    "# Empty list in the case of logistic regression\n",
    "hidden_units = []\n",
    "train_size = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance using the whole training set = 0.71\n"
     ]
    }
   ],
   "source": [
    "d, difficulty = 50, 1\n",
    "num_classes = 2\n",
    "tol = 0.03\n",
    "target_accuracy = 0.7\n",
    "important_dims = 5\n",
    "clf = return_model(model, solver='liblinear', hidden_units=tuple(hidden_units))\n",
    "_param = 1.0\n",
    "for _ in range(100):\n",
    "    X_raw = np.random.multivariate_normal(mean=np.zeros(d), cov = np.eye(d), \n",
    "                                          size=train_size + 5000)\n",
    "    _, y_raw, _, _ = label_generator(\n",
    "        problem, X_raw, param = _param,  difficulty = difficulty, important=important_dims)\n",
    "    clf.fit(X_raw[:train_size], y_raw[:train_size])\n",
    "    test_acc = clf.score(X_raw[train_size:], y_raw[train_size:])\n",
    "    if test_acc > target_accuracy:\n",
    "        break\n",
    "    _param *= 1.1\n",
    "print('Performance using the whole training set = {0:.2f}'.format(test_acc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running\n",
    "\n",
    "Now let's create the instance that takes cares of computing all the algorithms for the data set. Here we run it several times one-after-another, but in a real-world scenario they could be run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LOO score calculations!\n",
      "LOO values calculated!\n"
     ]
    }
   ],
   "source": [
    "X, y = X_raw[:train_size], y_raw[:train_size]\n",
    "X_test, y_test = X_raw[train_size:], y_raw[train_size:]\n",
    "model = 'logistic'\n",
    "problem = 'classification'\n",
    "num_test = 1000\n",
    "directory = './temp'\n",
    "dshap = DShap(X, y, X_test, y_test, num_test, \n",
    "              sources=None, \n",
    "              sample_weight=None,\n",
    "              model_family=model, \n",
    "              metric='accuracy',\n",
    "              overwrite=True,\n",
    "              directory=directory, seed=0)\n",
    "dshap.run(100, 0.1, g_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOO values calculated!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Session'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32md:\\code\\git repositories\\dataval\\notebooks\\../src/DataShap\\DShap.py:435\u001b[0m, in \u001b[0;36mDShap._g_shap\u001b[1;34m(self, iterations, err, learning_rate, sources)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 435\u001b[0m     learning_rate \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mg_shap_lr\n\u001b[0;32m    436\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DShap' object has no attribute 'g_shap_lr'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m directory \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./temp\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      7\u001b[0m dshap \u001b[39m=\u001b[39m DShap(X, y, X_test, y_test, num_test, model_family\u001b[39m=\u001b[39mmodel, metric\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m               directory\u001b[39m=\u001b[39mdirectory, seed\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m dshap\u001b[39m.\u001b[39;49mrun(\u001b[39m100\u001b[39;49m, \u001b[39m0.1\u001b[39;49m)\n",
      "File \u001b[1;32md:\\code\\git repositories\\dataval\\notebooks\\../src/DataShap\\DShap.py:239\u001b[0m, in \u001b[0;36mDShap.run\u001b[1;34m(self, save_every, err, tolerance, g_run, loo_run)\u001b[0m\n\u001b[0;32m    237\u001b[0m         g_run \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    238\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 239\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_g_shap(save_every, sources\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msources)\n\u001b[0;32m    240\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvals_g \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmem_g, \u001b[39m0\u001b[39m)\n\u001b[0;32m    241\u001b[0m \u001b[39mif\u001b[39;00m tmc_run:\n",
      "File \u001b[1;32md:\\code\\git repositories\\dataval\\notebooks\\../src/DataShap\\DShap.py:437\u001b[0m, in \u001b[0;36mDShap._g_shap\u001b[1;34m(self, iterations, err, learning_rate, sources)\u001b[0m\n\u001b[0;32m    435\u001b[0m         learning_rate \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg_shap_lr\n\u001b[0;32m    436\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m--> 437\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg_shap_lr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_one_step_lr()\n\u001b[0;32m    438\u001b[0m         learning_rate \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg_shap_lr\n\u001b[0;32m    439\u001b[0m model \u001b[39m=\u001b[39m ShapNN(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproblem, batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, max_epochs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m    440\u001b[0m              learning_rate\u001b[39m=\u001b[39mlearning_rate, weight_decay\u001b[39m=\u001b[39m\u001b[39m0.\u001b[39m,\n\u001b[0;32m    441\u001b[0m              validation_fraction\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msgd\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    442\u001b[0m              address\u001b[39m=\u001b[39maddress, hidden_units\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_units)\n",
      "File \u001b[1;32md:\\code\\git repositories\\dataval\\notebooks\\../src/DataShap\\DShap.py:406\u001b[0m, in \u001b[0;36mDShap._one_step_lr\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    404\u001b[0m accs \u001b[39m=\u001b[39m []\n\u001b[0;32m    405\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[1;32m--> 406\u001b[0m     model\u001b[39m.\u001b[39;49mfit(np\u001b[39m.\u001b[39;49mzeros((\u001b[39m0\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX\u001b[39m.\u001b[39;49mshape[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my)\n\u001b[0;32m    407\u001b[0m     model\u001b[39m.\u001b[39mfit(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my)\n\u001b[0;32m    408\u001b[0m     accs\u001b[39m.\u001b[39mappend(model\u001b[39m.\u001b[39mscore(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_test, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_test))\n",
      "File \u001b[1;32md:\\code\\git repositories\\dataval\\notebooks\\../src/DataShap\\sk_utils.py:151\u001b[0m, in \u001b[0;36mShapNN.fit\u001b[1;34m(self, X, y, X_val, y_val, sources, max_epochs, batch_size, save, load, sample_weight, metric)\u001b[0m\n\u001b[0;32m    149\u001b[0m         config \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mConfigProto()\n\u001b[0;32m    150\u001b[0m         config\u001b[39m.\u001b[39mgpu_options\u001b[39m.\u001b[39mallow_growth\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msess \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mSession(config\u001b[39m=\u001b[39mconfig)\n\u001b[0;32m    152\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mas_default():\n\u001b[0;32m    153\u001b[0m     tf\u001b[39m.\u001b[39mset_random_seed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_seed)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
     ]
    }
   ],
   "source": [
    "X, y = X_raw[:100], y_raw[:100]\n",
    "X_test, y_test = X_raw[100:], y_raw[100:]\n",
    "model = 'logistic'\n",
    "problem = 'classification'\n",
    "num_test = 1000\n",
    "directory = './temp'\n",
    "dshap = DShap(X, y, X_test, y_test, num_test, model_family=model, metric='accuracy',\n",
    "              directory=directory, seed=1)\n",
    "dshap.run(100, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X_raw[:100], y_raw[:100]\n",
    "X_test, y_test = X_raw[100:], y_raw[100:]\n",
    "model = 'logistic'\n",
    "problem = 'classification'\n",
    "num_test = 1000\n",
    "directory = './temp'\n",
    "dshap = DShap(X, y, X_test, y_test, num_test, model_family=model, metric='accuracy',\n",
    "              directory=directory, seed=2)\n",
    "dshap.run(100, 0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we merge results for the parallel runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dshap.merge_results()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the convergence plots of the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence_plots(dshap.marginals_tmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence_plots(dshap.marginals_g)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see the effect of removing high valuen points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dshap.performance_plots([dshap.vals_tmc, dshap.vals_g, dshap.vals_loo], num_plot_markers=20,\n",
    "                       sources=dshap.sources)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
