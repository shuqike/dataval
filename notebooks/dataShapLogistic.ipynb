{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../src/DataShap/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from DShap import DShap\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sk_utils import *\n",
    "%matplotlib inline\n",
    "MEM_DIR = './'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a calssification problem and use the a losigitic regression model for a small data set of size 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem, model = 'classification', 'logistic'\n",
    "# Empty list in the case of logistic regression\n",
    "hidden_units = []\n",
    "train_size = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance using the whole training set = 0.73\n"
     ]
    }
   ],
   "source": [
    "d, difficulty = 50, 1\n",
    "num_classes = 2\n",
    "tol = 0.03\n",
    "target_accuracy = 0.7\n",
    "important_dims = 5\n",
    "clf = return_model(model, solver='liblinear', hidden_units=tuple(hidden_units))\n",
    "_param = 1.0\n",
    "for _ in range(100):\n",
    "    X_raw = np.random.multivariate_normal(mean=np.zeros(d), cov = np.eye(d), \n",
    "                                          size=train_size + 5000)\n",
    "    _, y_raw, _, _ = label_generator(\n",
    "        problem, X_raw, param = _param,  difficulty = difficulty, important=important_dims)\n",
    "    clf.fit(X_raw[:train_size], y_raw[:train_size])\n",
    "    test_acc = clf.score(X_raw[train_size:], y_raw[train_size:])\n",
    "    if test_acc > target_accuracy:\n",
    "        break\n",
    "    _param *= 1.1\n",
    "print('Performance using the whole training set = {0:.2f}'.format(test_acc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running\n",
    "\n",
    "Now let's create the instance that takes cares of computing all the algorithms for the data set. Here we run it several times one-after-another, but in a real-world scenario they could be run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LOO score calculations!\n",
      "LOO values calculated!\n"
     ]
    }
   ],
   "source": [
    "X, y = X_raw[:train_size], y_raw[:train_size]\n",
    "X_test, y_test = X_raw[train_size:], y_raw[train_size:]\n",
    "model = 'logistic'\n",
    "problem = 'classification'\n",
    "num_test = 1000\n",
    "directory = './temp'\n",
    "dshap = DShap(X, y, X_test, y_test, num_test, \n",
    "              sources=None, \n",
    "              sample_weight=None,\n",
    "              model_family=model, \n",
    "              metric='accuracy',\n",
    "              overwrite=True,\n",
    "              directory=directory, seed=0)\n",
    "dshap.run(100, 0.1, g_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOO values calculated!\n"
     ]
    }
   ],
   "source": [
    "X, y = X_raw[:100], y_raw[:100]\n",
    "X_test, y_test = X_raw[100:], y_raw[100:]\n",
    "model = 'logistic'\n",
    "problem = 'classification'\n",
    "num_test = 1000\n",
    "directory = './temp'\n",
    "dshap = DShap(X, y, X_test, y_test, num_test, model_family=model, metric='accuracy',\n",
    "              directory=directory, seed=1)\n",
    "dshap.run(100, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOO values calculated!\n"
     ]
    }
   ],
   "source": [
    "X, y = X_raw[:100], y_raw[:100]\n",
    "X_test, y_test = X_raw[100:], y_raw[100:]\n",
    "model = 'logistic'\n",
    "problem = 'classification'\n",
    "num_test = 1000\n",
    "directory = './temp'\n",
    "dshap = DShap(X, y, X_test, y_test, num_test, model_family=model, metric='accuracy',\n",
    "              directory=directory, seed=2)\n",
    "dshap.run(100, 0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we merge results for the parallel runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./temp\\mem_tmc_0000.pkl\n",
      "./temp\\mem_tmc_0001.pkl\n",
      "./temp\\mem_tmc_0002.pkl\n",
      "./temp\\mem_tmc_0003.pkl\n",
      "./temp\\mem_tmc_0004.pkl\n",
      "./temp\\mem_tmc_0005.pkl\n",
      "./temp\\mem_tmc_0006.pkl\n",
      "./temp\\mem_g_0000.pkl\n",
      "./temp\\mem_g_0001.pkl\n",
      "./temp\\mem_g_0002.pkl\n",
      "./temp\\mem_g_0003.pkl\n",
      "./temp\\mem_g_0004.pkl\n",
      "./temp\\mem_g_0005.pkl\n",
      "./temp\\mem_g_0006.pkl\n"
     ]
    }
   ],
   "source": [
    "dshap.merge_results()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the convergence plots of the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AronQ\\AppData\\Local\\Temp\\ipykernel_24032\\2070795796.py:2: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "convergence_plots(dshap.marginals_tmc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AronQ\\AppData\\Local\\Temp\\ipykernel_24032\\4083960907.py:2: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "convergence_plots(dshap.marginals_g)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see the effect of removing high valuen points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AronQ\\AppData\\Local\\Temp\\ipykernel_24032\\2058161093.py:3: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "dshap.performance_plots([dshap.vals_tmc, dshap.vals_g, dshap.vals_loo], num_plot_markers=20,\n",
    "                       sources=dshap.sources)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
