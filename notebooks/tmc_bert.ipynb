{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AronQ\\.conda\\envs\\flenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from src.frameworks import TruncatedMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset yelp_review_full (C:/Users/AronQ/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf)\n",
      "100%|██████████| 2/2 [00:00<00:00, 47.62it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"yelp_review_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 3,\n",
       " 'text': \"Been going to Dr. Goldberg for over 10 years. I think I was one of his 1st patients when he started at MHMG. He's been great over the years and is really all about the big picture. It is because of him, not my now former gyn Dr. Markoff, that I found out I have fibroids. He explores all options with you and is very patient and understanding. He doesn't judge and asks all the right questions. Very thorough and wants to be kept in the loop on every aspect of your medical health and your life.\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\AronQ\\.cache\\huggingface\\datasets\\yelp_review_full\\yelp_review_full\\1.0.0\\e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf\\cache-aad1af4c7095bfa1.arrow\n",
      "Loading cached processed dataset at C:\\Users\\AronQ\\.cache\\huggingface\\datasets\\yelp_review_full\\yelp_review_full\\1.0.0\\e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf\\cache-29f27748f0b54d01.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\AronQ\\.cache\\huggingface\\datasets\\yelp_review_full\\yelp_review_full\\1.0.0\\e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf\\cache-11a7619c6a3c070f.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\AronQ\\.cache\\huggingface\\datasets\\yelp_review_full\\yelp_review_full\\1.0.0\\e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf\\cache-3c5c2a245be1b332.arrow\n"
     ]
    }
   ],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(small_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(small_train_dataset['text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell output should contain a warning like: \"Some weights of the model checkpoint at bert-base-cased were not used when initializing...\".\n",
    "\n",
    "This is OK as we are not using the pooler layer in order to compute the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "dshap = TruncatedMC(train_dataset=small_train_dataset, X_train=small_train_dataset['text'], X_test=small_eval_dataset['text'], test_dataset=small_eval_dataset, model_family='bert-base-cased', num_labels=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the initial accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dshap.random_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate leave-one-out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'init_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32md:\\code\\git repositories\\dataval\\notebooks\\..\\src\\frameworks\\monte_carlo.py:259\u001b[0m, in \u001b[0;36mTruncatedMC.run\u001b[1;34m(self, save_every, err, tol, do_tmc, do_gshap, do_loo)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 259\u001b[0m     \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvals_loo)\n\u001b[0;32m    260\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TruncatedMC' object has no attribute 'vals_loo'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dshap\u001b[39m.\u001b[39;49mrun(save_every\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, err\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, do_loo\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, do_tmc\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, do_gshap\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32md:\\code\\git repositories\\dataval\\notebooks\\..\\src\\frameworks\\monte_carlo.py:262\u001b[0m, in \u001b[0;36mTruncatedMC.run\u001b[1;34m(self, save_every, err, tol, do_tmc, do_gshap, do_loo)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    261\u001b[0m         tqdm\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39mCalculate leave-one-out\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_calc_loo()\n\u001b[0;32m    264\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmem_tmc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_data))\n\u001b[0;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmem_gshap \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_data))\n",
      "File \u001b[1;32md:\\code\\git repositories\\dataval\\notebooks\\..\\src\\frameworks\\monte_carlo.py:87\u001b[0m, in \u001b[0;36mTruncatedMC._calc_loo\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_calc_loo\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     85\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Calculate leave-one-out values for the given metric.\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mreset()\n\u001b[0;32m     88\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mfit(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_dataset, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_dataset)\n\u001b[0;32m     89\u001b[0m     baseline_val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mperf_metric(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_dataset)\n",
      "File \u001b[1;32md:\\code\\git repositories\\dataval\\notebooks\\..\\src\\models\\classifier.py:70\u001b[0m, in \u001b[0;36mCasifier.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39m# Re-initialize weights for data valuation\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pretrained \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model\u001b[39m.\u001b[39;49minit_weights()\n\u001b[0;32m     71\u001b[0m \u001b[39m# Put model into device\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_device)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'init_weights'"
     ]
    }
   ],
   "source": [
    "dshap.run(save_every=100, err=0.1, do_loo=True, do_tmc=False, do_gshap=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
