{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import time\n",
    "from collections import namedtuple\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import src.utils as utils\n",
    "from src.models import LeNetMNIST, ResVestimatorMNIST, R18VestimatorMNIST, Vestimator, LeVestimatorMNIST\n",
    "from src.frameworks.online_dvrl import Odvrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Parameters = namedtuple('Parameters', [\n",
    "    'saving_path',\n",
    "    'val_batch_size',\n",
    "    'epochs',\n",
    "    'device',\n",
    "    'learning_rate',\n",
    "    'num_workers',\n",
    "    # 'input_dim',\n",
    "    # 'hidden_dim',\n",
    "    # 'output_dim',\n",
    "    # 'layer_number',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = Parameters(\n",
    "    saving_path='../logs',\n",
    "    val_batch_size=128,\n",
    "    epochs=15,\n",
    "    device='cuda',\n",
    "    learning_rate=1e-6,\n",
    "    num_workers=1,\n",
    "    # input_dim=794,\n",
    "    # hidden_dim=100,\n",
    "    # output_dim=10,\n",
    "    # layer_number=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 10\n",
    "noise_level = 0.2\n",
    "seed = 3407\n",
    "num_weak = 30\n",
    "pred_model = LeNetMNIST()\n",
    "val_model = LeNetMNIST()\n",
    "value_estimator = LeVestimatorMNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model.classify(data)\n",
    "        loss = torch.nn.functional.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('../data/pretrained_models/pretrained_levestimator.pt'):\n",
    "    value_estimator.load_state_dict(\n",
    "        torch.load('../data/pretrained_models/pretrained_levestimator.pt')\n",
    "    )\n",
    "else:\n",
    "    train_dataset = torchvision.datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "    optimizer = torch.optim.Adadelta(value_estimator.parameters(), lr=1.0)\n",
    "    value_estimator.to('cuda')\n",
    "    for epoch in tqdm(range(14)):\n",
    "        train(value_estimator, 'cuda', train_loader, optimizer, epoch)\n",
    "    torch.save(\n",
    "        value_estimator.state_dict(),\n",
    "        '../data/pretrained_models/pretrained_levestimator.pt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2637b1e3f70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run 'pretrain_mnist.ipynb' first\n",
    "# then load this pretrained model\n",
    "state_dict = torch.load(\"../data/pretrained_models/pretrained_lenetmnist.pt\")\n",
    "val_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test, noisy_idxs = utils.create_noisy_mnist(method='uniform', noise_level=noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  6,  9, 23, 28, 34, 36, 41, 52, 53, 57, 63, 66, 66, 68, 74, 82,\n",
       "       82, 82, 86])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_idxs.sort()\n",
    "noisy_idxs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(x_train)\n",
    "y_train = torch.tensor(y_train)\n",
    "test_data = torchvision.datasets.MNIST('../data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = Odvrl(num_weak=num_weak, pred_model=pred_model, val_model=val_model, value_estimator=value_estimator, parameters=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fri May  5 17:03:06 2023'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.asctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 0 epoch 0, the reward is 0.029400, the prob is 1.000000\n",
      "At step 0 epoch 1, the reward is 0.075300, the prob is 1.000000\n",
      "At step 0 epoch 2, the reward is 0.109200, the prob is 1.000000\n",
      "At step 0 epoch 3, the reward is 0.137000, the prob is 1.000000\n",
      "At step 0 epoch 4, the reward is 0.150400, the prob is 1.000000\n",
      "At step 0 epoch 5, the reward is 0.167100, the prob is 1.000000\n",
      "At step 0 epoch 6, the reward is 0.176600, the prob is 1.000000\n",
      "At step 0 epoch 7, the reward is 0.183600, the prob is 1.000000\n",
      "At step 0 epoch 8, the reward is 0.185900, the prob is 1.000000\n",
      "At step 0 epoch 9, the reward is 0.193400, the prob is 1.000000\n",
      "At step 0 epoch 10, the reward is 0.196400, the prob is 1.000000\n",
      "At step 0 epoch 11, the reward is 0.197600, the prob is 1.000000\n",
      "At step 0 epoch 12, the reward is 0.197500, the prob is 1.000000\n",
      "At step 0 epoch 13, the reward is 0.200000, the prob is 1.000000\n",
      "At step 0 epoch 14, the reward is 0.198900, the prob is 1.000000\n",
      "[2943 2018 4710 2024 4708 4707 2027 2015 2031 2034]\n",
      "[ 6  6  9 23 28 34 36 41 52 53]\n",
      "discover rate: 0.1742957746478873\n",
      "At step 1 epoch 0, the reward is 0.200000, the prob is 1.000000\n",
      "At step 1 epoch 1, the reward is 0.202300, the prob is 1.000000\n",
      "At step 1 epoch 2, the reward is 0.218800, the prob is 1.000000\n",
      "At step 1 epoch 3, the reward is 0.247000, the prob is 1.000000\n",
      "At step 1 epoch 4, the reward is 0.257000, the prob is 1.000000\n",
      "At step 1 epoch 5, the reward is 0.266400, the prob is 1.000000\n",
      "At step 1 epoch 6, the reward is 0.276100, the prob is 1.000000\n",
      "At step 1 epoch 7, the reward is 0.273000, the prob is 1.000000\n",
      "At step 1 epoch 8, the reward is 0.276300, the prob is 1.000000\n"
     ]
    }
   ],
   "source": [
    "subset_len = num_data // T\n",
    "for t in range(T):\n",
    "    start_id = t * subset_len\n",
    "    end_id = min((t + 1) * subset_len, num_data)\n",
    "    engine.one_step(\n",
    "        t, \n",
    "        X=x_train[start_id:end_id], \n",
    "        y=y_train[start_id:end_id], \n",
    "        val_dataset=test_data, \n",
    "    )\n",
    "    utils.super_save()\n",
    "    current_noisy_idxs = np.extract((noisy_idxs >= start_id) & (noisy_idxs < end_id), noisy_idxs)\n",
    "    current_corrupted_num = len(current_noisy_idxs)\n",
    "    if current_corrupted_num > 0:\n",
    "        values = []\n",
    "        for i in range(subset_len // 128):\n",
    "            part_values = engine.evaluate(x_train[start_id+i*128: start_id+min((i+1)*128, num_data)], y_train[start_id+i*128: start_id+min((i+1)*128, num_data)])\n",
    "            values = np.concatenate((values, part_values))\n",
    "            utils.super_save()\n",
    "        guess_idxs = np.argsort(values)\n",
    "        print(guess_idxs[:10])\n",
    "        print(current_noisy_idxs[:10])\n",
    "        discover_rate = len(np.intersect1d(start_id+guess_idxs[:current_corrupted_num], current_noisy_idxs)) / current_corrupted_num\n",
    "        print('discover rate: {}'.format(discover_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.asctime()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
